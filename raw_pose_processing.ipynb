{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Poses from Amass Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "\n",
    "from human_body_prior.tools.omni_tools import copy2cpu as c2c\n",
    "\n",
    "os.environ['PYOPENGL_PLATFORM'] = 'egl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please remember to download the following subdataset from AMASS website: https://amass.is.tue.mpg.de/download.php. Note only download the <u>SMPL+H G</u> data.\n",
    "* ACCD (ACCD)\n",
    "* HDM05 (MPI_HDM05)\n",
    "* TCDHands (TCD_handMocap)\n",
    "* SFU (SFU)\n",
    "* BMLmovi (BMLmovi)\n",
    "* CMU (CMU)\n",
    "* Mosh (MPI_mosh)\n",
    "* EKUT (EKUT)\n",
    "* KIT  (KIT)\n",
    "* Eyes_Janpan_Dataset (Eyes_Janpan_Dataset)\n",
    "* BMLhandball (BMLhandball)\n",
    "* Transitions (Transitions_mocap)\n",
    "* PosePrior (MPI_Limits)\n",
    "* HumanEva (HumanEva)\n",
    "* SSM (SSM_synced)\n",
    "* DFaust (DFaust_67)\n",
    "* TotalCapture (TotalCapture)\n",
    "* BMLrub (BioMotionLab_NTroje)\n",
    "\n",
    "### Unzip all datasets. In the bracket we give the name of the unzipped file folder. Please correct yours to the given names if they are not the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place all files under the directory **./amass_data/**. The directory structure shoud look like the following:  \n",
    "./amass_data/  \n",
    "./amass_data/ACCAD/  \n",
    "./amass_data/BioMotionLab_NTroje/  \n",
    "./amass_data/BMLhandball/  \n",
    "./amass_data/BMLmovi/   \n",
    "./amass_data/CMU/  \n",
    "./amass_data/DFaust_67/  \n",
    "./amass_data/EKUT/  \n",
    "./amass_data/Eyes_Japan_Dataset/  \n",
    "./amass_data/HumanEva/  \n",
    "./amass_data/KIT/  \n",
    "./amass_data/MPI_HDM05/  \n",
    "./amass_data/MPI_Limits/  \n",
    "./amass_data/MPI_mosh/  \n",
    "./amass_data/SFU/  \n",
    "./amass_data/SSM_synced/  \n",
    "./amass_data/TCD_handMocap/  \n",
    "./amass_data/TotalCapture/  \n",
    "./amass_data/Transitions_mocap/  \n",
    "\n",
    "**Please make sure the file path are correct, otherwise it can not succeed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the device to run the body model on.\n",
    "comp_device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from human_body_prior.body_model.body_model import BodyModel\n",
    "\n",
    "male_bm_path = './body_models/smplh/male/model.npz'\n",
    "male_dmpl_path = './body_models/dmpls/male/model.npz'\n",
    "\n",
    "female_bm_path = './body_models/smplh/female/model.npz'\n",
    "female_dmpl_path = './body_models/dmpls/female/model.npz'\n",
    "\n",
    "infant_bm_path = './body_models/smplh/infant/model.npz'\n",
    "infant_dmpl_path = './body_models/dmpls/infant/model.npz'\n",
    "\n",
    "num_betas = 10 # number of body parameters\n",
    "num_dmpls = 0 # number of DMPL parameters\n",
    "\n",
    "num_infant_betas = 8 # number of body parameters\n",
    "num_infant_dmpls = 0 # number of DMPL parameters\n",
    "\n",
    "male_bm = BodyModel(bm_fname=male_bm_path, num_betas=num_betas, num_dmpls=num_dmpls, dmpl_fname=male_dmpl_path).to(comp_device)\n",
    "faces = c2c(male_bm.f)\n",
    "\n",
    "female_bm = BodyModel(bm_fname=female_bm_path, num_betas=num_betas, num_dmpls=num_dmpls, dmpl_fname=female_dmpl_path).to(comp_device)\n",
    "infant_bm = BodyModel(bm_fname=infant_bm_path, num_betas=num_infant_betas).to(comp_device) ## run without dmpls because they aren't available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "data_folder='/workspaces/HumanML3D/infant_poses'\n",
    "save_folder='/workspaces/HumanML3D/all_infant_poses' \n",
    "\n",
    "# Get all .pkl files in the specified folder\n",
    "files = [f for f in os.listdir(data_folder) if f.endswith('.pkl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fname(file):\n",
    "\n",
    "    if \"-\" in file.split(\"_\")[0]:\n",
    "        fname = f'{file.split(\"_\")[0].split(\"-\")[1]}_{file.split(\"_\")[1]}_{file.split(\"_\")[2]}'\n",
    "    else:\n",
    "        fname = f'{file.split(\"_\")[1]}_{file.split(\"_\")[2]}_{file.split(\"_\")[3]}'\n",
    "\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been organized into subfolders.\n"
     ]
    }
   ],
   "source": [
    "# Loop through the files and organize them into subfolders\n",
    "for file in files:\n",
    "\n",
    "    prefix = get_fname(file)\n",
    "    \n",
    "    # Create the subfolder path\n",
    "    subfolder_path = os.path.join(save_folder, prefix)\n",
    "    #print(subfolder_path)\n",
    "    \n",
    "    # Create the subfolder if it doesn't exist\n",
    "    if not os.path.exists(subfolder_path):\n",
    "        os.makedirs(subfolder_path)\n",
    "    \n",
    "    # Move the file into the corresponding subfolder\n",
    "    #print(os.path.join(data_folder, file), subfolder_path)\n",
    "\n",
    "    if not os.path.exists(os.path.join(subfolder_path, file)):\n",
    "        shutil.copy(os.path.join(data_folder, file), subfolder_path)\n",
    "\n",
    "print(\"Files have been organized into subfolders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "def get_poses(folder):\n",
    "    poses, trans, betas = [], [],[]\n",
    "\n",
    "    for pkl_file in os.listdir(folder):\n",
    "        with open(os.path.join(folder, pkl_file), 'rb') as f:\n",
    "\n",
    "            pkl_poses = pkl.load(f)\n",
    "\n",
    "            betas.append(list(pkl_poses['betas'][0]))\n",
    "            poses.append(list(pkl_poses['body_pose'][0]))\n",
    "            trans.append(list(pkl_poses['camera_translation'][0]))\n",
    "\n",
    "    new_dict = {'betas':betas,\n",
    "        'trans':trans,\n",
    "        'poses':poses,\n",
    "        'mocap_framerate':int(15),\n",
    "        'gender':'infant'\n",
    "        }\n",
    "    \n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved successfully\n"
     ]
    }
   ],
   "source": [
    "#TODO: Change the path to the folder containing the subfolders\n",
    "# get all poses from the subfolders\n",
    "\n",
    "file_details = []\n",
    "file_id = 0\n",
    "\n",
    "for subfolder in os.listdir(save_folder):\n",
    "    pkl_path = os.path.join(save_folder, subfolder)\n",
    "    try:       \n",
    "        all_poses = get_poses(pkl_path)\n",
    "\n",
    "        # Check if 'betas', 'trans', or 'poses' fields are empty\n",
    "        if not (all_poses['betas'] and all_poses['trans'] and all_poses['poses']):\n",
    "            print(f\"Skipping saving {subfolder} as 'betas', 'trans', or 'poses' are empty\")\n",
    "        \n",
    "        else:\n",
    "            out_dir = f'/workspaces/HumanML3D/amass_data/Infant/{subfolder}'\n",
    "            out_file = f'infant_{subfolder}.npz'\n",
    "\n",
    "            if not os.path.exists(out_dir):\n",
    "                os.makedirs(out_dir)\n",
    "\n",
    "            #source_path = f'./all_infant_poses/CHOP/{gma_id}/infant_{gma_id}.npy'  # Replace with your source path\n",
    "            source_path = f'./pose_data/Infant/{subfolder}/infant_{subfolder}.npy'\n",
    "            new_name = f'{str(file_id).zfill(5)}.npy'  # Replace with your new name\n",
    "            start_frame = 0\n",
    "            end_frame = len(all_poses['poses'])\n",
    "\n",
    "            # Store the details for the CSV file\n",
    "            file_details.append([source_path, start_frame, end_frame, new_name])\n",
    "            file_id += 1\n",
    "            \n",
    "            np.savez(os.path.join(out_dir,out_file), **all_poses)\n",
    "            #print(f'saving poses for {subfolder}')\n",
    "    except:\n",
    "        continue\n",
    "        print(f'no good poses for {subfolder}')\n",
    "\n",
    "# Write to CSV file after the loop\n",
    "with open('index_infant.csv', mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['source_path', 'start_frame', 'end_frame', 'new_name'])\n",
    "    for details in file_details:\n",
    "        csv_writer.writerow(details)\n",
    "\n",
    "print(\"CSV file saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "folders = []\n",
    "dataset_names = []\n",
    "for root, dirs, files in os.walk('./amass_data'):\n",
    "#     print(root, dirs, files)\n",
    "#     for folder in dirs:\n",
    "#         folders.append(os.path.join(root, folder))\n",
    "    folders.append(root)\n",
    "    for name in files:\n",
    "        dataset_name = root.split('/')[2]\n",
    "        if dataset_name not in dataset_names:\n",
    "            dataset_names.append(dataset_name)\n",
    "        paths.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_root = './pose_data'\n",
    "save_folders = [folder.replace('./amass_data', './pose_data') for folder in folders]\n",
    "for folder in save_folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "group_path = [[path for path in paths if name in path] for name in dataset_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_matrix = np.array([[1.0, 0.0, 0.0],\n",
    "                            [0.0, 0.0, 1.0],\n",
    "                            [0.0, 1.0, 0.0]])\n",
    "ex_fps = 15\n",
    "def amass_to_pose(src_path, save_path):\n",
    "    bdata = np.load(src_path, allow_pickle=True)\n",
    "    fps = 0\n",
    "    try:\n",
    "        fps = bdata['mocap_framerate']\n",
    "        frame_number = bdata['trans'].shape[0]\n",
    "    except:\n",
    "#         print(list(bdata.keys()))\n",
    "        return fps\n",
    "    \n",
    "    fId = 0 # frame id of the mocap sequence\n",
    "    pose_seq = []\n",
    "    \n",
    "    if bdata['gender'] == 'male':\n",
    "        bm = male_bm\n",
    "    if bdata['gender'] == 'female':\n",
    "        bm = female_bm\n",
    "    if bdata['gender'] == 'infant':\n",
    "        bm = infant_bm\n",
    "    \n",
    "    down_sample = int(fps / ex_fps)\n",
    "#     print(frame_number)\n",
    "#     print(fps)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for fId in range(0, frame_number, down_sample):\n",
    "            root_orient = torch.Tensor(bdata['poses'][fId:fId+1, :3]).to(comp_device) # controls the global root orientation\n",
    "            pose_body = torch.Tensor(bdata['poses'][fId:fId+1, 3:66]).to(comp_device) # controls the body\n",
    "            pose_hand = torch.Tensor(bdata['poses'][fId:fId+1, 66:]).to(comp_device) # controls the finger articulation\n",
    "            betas = torch.Tensor(bdata['betas'][:num_infant_betas][np.newaxis]).to(comp_device) # controls the body shape\n",
    "            trans = torch.Tensor(bdata['trans'][fId:fId+1]).to(comp_device)    \n",
    "            body=bm(body_pose=pose_body)\n",
    "            #body = bm(pose_body=pose_body, pose_hand=None, betas=betas, root_orient=root_orient)\n",
    "            joint_loc = body.Jtr[0] + trans\n",
    "            pose_seq.append(joint_loc.unsqueeze(0))\n",
    "    \n",
    "    pose_seq = torch.cat(pose_seq, dim=0)\n",
    "    \n",
    "    pose_seq_np = pose_seq.detach().cpu().numpy()\n",
    "    pose_seq_np_n = np.dot(pose_seq_np, trans_matrix)\n",
    "    \n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    np.save(save_path, pose_seq_np_n)\n",
    "    \n",
    "    return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_path = group_path\n",
    "all_count = sum([len(paths) for paths in group_path])\n",
    "cur_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Transitions_mocap. Only processing Infant data for now\n",
      "Skipping DFaust_67. Only processing Infant data for now\n",
      "Skipping TotalCapture. Only processing Infant data for now\n",
      "Skipping Eyes_Japan_Dataset. Only processing Infant data for now\n",
      "Skipping BMLhandball. Only processing Infant data for now\n",
      "Skipping TCD_handMocap. Only processing Infant data for now\n",
      "Skipping SFU. Only processing Infant data for now\n",
      "Infant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Infant:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./amass_data/Infant/19_2_1/infant_19_2_1.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Infant:   8%|▊         | 1/13 [00:02<00:34,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./amass_data/Infant/26_1_1/infant_26_1_1.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Infant:  15%|█▌        | 2/13 [00:04<00:20,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./amass_data/Infant/11_2_1/infant_11_2_1.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Infant:  23%|██▎       | 3/13 [00:11<00:44,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./amass_data/Infant/18_2_1/infant_18_2_1.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Infant:  31%|███       | 4/13 [00:13<00:29,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./amass_data/Infant/27_1_1/infant_27_1_1.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Infant:  38%|███▊      | 5/13 [00:13<00:19,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./amass_data/Infant/11_1_1/infant_11_1_1.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Infant:  46%|████▌     | 6/13 [00:18<00:22,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./amass_data/Infant/15_1_1/infant_15_1_1.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Infant:  54%|█████▍    | 7/13 [00:29<00:33,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./amass_data/Infant/25_1_gp2/infant_25_1_gp2.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Infant:  62%|██████▏   | 8/13 [00:29<00:19,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./amass_data/Infant/11_2_2/infant_11_2_2.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Infant:  69%|██████▉   | 9/13 [00:34<00:17,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./amass_data/Infant/18_1_1/infant_18_1_1.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Infant:  77%|███████▋  | 10/13 [00:36<00:10,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./amass_data/Infant/20_1_1/infant_20_1_1.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Infant:  85%|████████▍ | 11/13 [00:40<00:07,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./amass_data/Infant/11_1_2/infant_11_1_2.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Infant:  92%|█████████▏| 12/13 [00:42<00:03,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./amass_data/Infant/23_1_1/infant_23_1_1.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Infant: 100%|██████████| 13/13 [00:44<00:00,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 15): 13/14068\n",
      "Skipping EKUT. Only processing Infant data for now\n",
      "Skipping KIT. Only processing Infant data for now\n",
      "Skipping SSM_synced. Only processing Infant data for now\n",
      "Skipping MPI_mosh. Only processing Infant data for now\n",
      "Skipping BMLmovi. Only processing Infant data for now\n",
      "Skipping BioMotionLab_NTroje. Only processing Infant data for now\n",
      "Skipping MPI_Limits. Only processing Infant data for now\n",
      "Skipping CMU. Only processing Infant data for now\n",
      "Skipping HumanEva. Only processing Infant data for now\n",
      "Skipping ACCAD. Only processing Infant data for now\n",
      "Skipping MPI_HDM05. Only processing Infant data for now\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for paths in group_path:\n",
    "    dataset_name = paths[0].split('/')[2]\n",
    "\n",
    "    if dataset_name == 'Infant':\n",
    "        print(dataset_name)\n",
    "        pbar = tqdm(paths)\n",
    "        pbar.set_description('Processing: %s'%dataset_name)\n",
    "        fps = 15\n",
    "        for path in pbar:\n",
    "            save_path = path.replace('./amass_data', './pose_data')\n",
    "\n",
    "            save_path = save_path[:-3] + 'npy'\n",
    "            print(path)\n",
    "\n",
    "            if os.path.isfile(save_path):\n",
    "                print(f'file exists, moving on')\n",
    "                continue\n",
    "            else:\n",
    "                fps = amass_to_pose(path, save_path)\n",
    "            \n",
    "        cur_count += len(paths)\n",
    "        print('Processed / All (fps %d): %d/%d'% (fps, cur_count, all_count) )\n",
    "        time.sleep(0.5)\n",
    "    else:\n",
    "        print(f'Skipping {dataset_name}. Only processing Infant data for now')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a few hours for all datasets, here we take one dataset as an example\n",
    "\n",
    "To accelerate the process, you could run multiple scripts like this at one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Transitions_mocap: 100%|██████████| 110/110 [00:01<00:00, 62.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 120): 110/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: DFaust_67: 100%|██████████| 139/139 [00:01<00:00, 112.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 60): 249/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: TotalCapture: 100%|██████████| 37/37 [00:00<00:00, 39.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 60): 286/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Eyes_Japan_Dataset: 100%|██████████| 750/750 [00:11<00:00, 64.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 120): 1036/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: BMLhandball: 100%|██████████| 659/659 [00:06<00:00, 97.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 120): 1695/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: TCD_handMocap: 100%|██████████| 62/62 [00:00<00:00, 113.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 120): 1757/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: SFU: 100%|██████████| 44/44 [00:00<00:00, 76.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 120): 1801/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: EKUT: 100%|██████████| 349/349 [00:03<00:00, 104.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 100): 2150/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: KIT: 100%|██████████| 4232/4232 [00:43<00:00, 97.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 100): 6382/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: SSM_synced: 100%|██████████| 30/30 [00:00<00:00, 101.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 120): 6412/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: MPI_mosh: 100%|██████████| 77/77 [00:00<00:00, 88.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 100): 6489/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: BMLmovi: 100%|██████████| 1887/1887 [00:17<00:00, 109.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 120): 8376/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: BioMotionLab_NTroje: 100%|██████████| 3061/3061 [00:32<00:00, 93.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 120): 11437/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: MPI_Limits: 100%|██████████| 35/35 [00:00<00:00, 59.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 120): 11472/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: CMU: 100%|██████████| 2088/2088 [00:24<00:00, 84.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 120): 13560/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: HumanEva: 100%|██████████| 28/28 [00:00<00:00, 81.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 120): 13588/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: ACCAD: 100%|██████████| 252/252 [00:02<00:00, 101.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 120): 13840/14055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: MPI_HDM05: 100%|██████████| 215/215 [00:03<00:00, 55.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 120): 14055/14055\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for paths in group_path:\n",
    "    dataset_name = paths[0].split('/')[2]\n",
    "    pbar = tqdm(paths)\n",
    "    pbar.set_description('Processing: %s'%dataset_name)\n",
    "    fps = 0\n",
    "    for path in pbar:\n",
    "        save_path = path.replace('./amass_data', './pose_data')\n",
    "        save_path = save_path[:-3] + 'npy'\n",
    "        fps = amass_to_pose(path, save_path)\n",
    "        \n",
    "    cur_count += len(paths)\n",
    "    print('Processed / All (fps %d): %d/%d'% (fps, cur_count, all_count) )\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will extract poses from **AMASS** dataset, and put them under directory **\"./pose_data\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source data from **HumanAct12** is already included in **\"./pose_data\"** in this repository. You need to **unzip** it right in this folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment, Mirror and Relocate Motions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs as cs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os.path import join as pjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_left_right(data):\n",
    "    assert len(data.shape) == 3 and data.shape[-1] == 3\n",
    "    data = data.copy()\n",
    "    data[..., 0] *= -1\n",
    "    right_chain = [2, 5, 8, 11, 14, 17, 19, 21]\n",
    "    left_chain = [1, 4, 7, 10, 13, 16, 18, 20]\n",
    "    left_hand_chain = [22, 23, 24, 34, 35, 36, 25, 26, 27, 31, 32, 33, 28, 29, 30]\n",
    "    right_hand_chain = [43, 44, 45, 46, 47, 48, 40, 41, 42, 37, 38, 39, 49, 50, 51]\n",
    "    tmp = data[:, right_chain]\n",
    "    data[:, right_chain] = data[:, left_chain]\n",
    "    data[:, left_chain] = tmp\n",
    "    if data.shape[1] > 24:\n",
    "        tmp = data[:, right_hand_chain]\n",
    "        data[:, right_hand_chain] = data[:, left_hand_chain]\n",
    "        data[:, left_hand_chain] = tmp\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFANT = True\n",
    "\n",
    "if INFANT:\n",
    "    index_path = './index_infant.csv'\n",
    "    save_dir = './infant_joints'\n",
    "else:\n",
    "    index_path = './index.csv'\n",
    "    save_dir = './joints'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "index_file = pd.read_csv(index_path)\n",
    "total_amount = index_file.shape[0]\n",
    "fps = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 706.14it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(total_amount)):\n",
    "    source_path = index_file.loc[i]['source_path']\n",
    "    new_name = index_file.loc[i]['new_name']\n",
    "    data = np.load(source_path)\n",
    "    start_frame = index_file.loc[i]['start_frame']\n",
    "    end_frame = index_file.loc[i]['end_frame']\n",
    "    if 'humanact12' not in source_path:\n",
    "        if 'Eyes_Japan_Dataset' in source_path:\n",
    "            data = data[3*fps:]\n",
    "        if 'MPI_HDM05' in source_path:\n",
    "            data = data[3*fps:]\n",
    "        if 'TotalCapture' in source_path:\n",
    "            data = data[1*fps:]\n",
    "        if 'MPI_Limits' in source_path:\n",
    "            data = data[1*fps:]\n",
    "        if 'Transitions_mocap' in source_path:\n",
    "            data = data[int(0.5*fps):]\n",
    "        data = data[start_frame:end_frame]\n",
    "        data[..., 0] *= -1\n",
    "    \n",
    "    data_m = swap_left_right(data)\n",
    "#     save_path = pjoin(save_dir, )\n",
    "    np.save(pjoin(save_dir, new_name), data)\n",
    "    np.save(pjoin(save_dir, 'M'+new_name), data_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_render",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
